{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Estos dos comandos evitan que haya que hacer reload cada vez que se modifica un paquete\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyQt5 in c:\\users\\candelaria\\appdata\\local\\conda\\conda\\envs\\redesitba\\lib\\site-packages (5.12.1)\n",
      "Requirement already satisfied: PyQt5_sip<4.20,>=4.19.14 in c:\\users\\candelaria\\appdata\\local\\conda\\conda\\envs\\redesitba\\lib\\site-packages (from PyQt5) (4.19.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyQt5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: pesos y alturas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con un dataset que registra el peso y la altura de 10000 personas, y buscaremos clasificar en hombres y mujeres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b7a28f3297fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/rn-2019-itba/Clase-4---LDA---QDA---RL---DT---RF/master/data/alturas-pesos-mils-train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/rn-2019-itba/Clase-4---LDA---QDA---RL---DT---RF/master/data/alturas-pesos-mils-test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Casos de train:'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Casos de test:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/rn-2019-itba/Clase-4---LDA---QDA---RL---DT---RF/master/data/alturas-pesos-mils-train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/rn-2019-itba/Clase-4---LDA---QDA---RL---DT---RF/master/data/alturas-pesos-mils-test.csv')\n",
    "print('Casos de train:' ,len(data.index))\n",
    "print('Casos de test:', len(test.index))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hombres = data.loc[data['Genero']=='Hombre'][['Peso','Altura']].values\n",
    "data_mujeres = data.loc[data['Genero']=='Mujer'][['Peso','Altura']].values\n",
    "data_hombres_test = test.loc[data['Genero']=='Hombre'][['Peso','Altura']].values\n",
    "data_mujeres_test = test.loc[data['Genero']=='Mujer'][['Peso','Altura']].values\n",
    "print(data_hombres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "f = plt.figure(figsize=(20,10))\n",
    "plt.scatter(data_hombres[:,0], data_hombres[:,1], color='b', s=2, label='Hombres')\n",
    "plt.scatter(data_mujeres[:,0], data_mujeres[:,1], color='r', s=2, label='Mujeres')\n",
    "plt.xlabel('Pesos [gramos]')\n",
    "plt.ylabel('Alturas [cms]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\\text{Bayes:    }  P(y=k | X) = \\frac{P(X | y=k) P(y=k)}{P(X)} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde un punto de vista de modelo generativo, podemos pensar que la probabilidad de que sea hombre y de que sea mujer dado que observamos una cierta combinación de pesos y alturas *a,p* es: \n",
    "\n",
    "$$P(Y=Mujer | A,P=a,p) = \\frac{P( A,P=a,p| Y=Mujer) P(Y=Mujer)}{P(A,P=a,p)}$$\n",
    "$$P(Y=Hombre | A,P=a,p) = \\frac{P( A,P=a,p| Y=Hombre) P(Y=Hombre)}{P(A,P=a,p)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Pero cómo podemos calcular $P(A,P=a,p| Y=Mujer)$ y $P( A,P=a,p| Y=Hombre)$? Dependerá de cómo modelemos la distribución de peso y altura para cada una de las dos clases.\n",
    "\n",
    "Una opción es modelar la distribución de las variables como una **distribución Gaussiana multivariable**. A diferencia de una Gaussiana univariable, donde los parámetros son únicamente la media y la varianza de esa variable, en este caso tendremos que parametrizar también de alguna forma la relación que existe entre las variables. Esto está representado en la matriz de covarianza $\\Sigma$, cuyo elemento en la posición i,j es la covarianza entre la i-ésima y la j-ésima variable.  La covarianza expresa la relación lineal entre un par de variables.\n",
    "\n",
    "En nuestro caso tendremos dos matrices de covarianza, ya que cada uno de nuestros modelos generadores (mujer y hombre) es una distribución Gaussiana multivariable distinta.\n",
    "\n",
    "$$ \\Sigma_{Mujer} =   \\begin{matrix} \\sigma_{\\frac{p,p}{Y=mujer}} & \\sigma_{\\frac{p,a}{Y=mujer}} \\\\ \\sigma_{\\frac{a,p}{Y=mujer}} & \\sigma_{\\frac{a,a}{Y=mujer}}\\end{matrix} $$\n",
    "$$ \\Sigma_{Hombre} =   \\begin{matrix} \\sigma_{\\frac{p,p}{Y=Hombre}} & \\sigma_{\\frac{p,a}{Y=Hombre}} \\\\ \\sigma_{\\frac{a,p}{Y=Hombre}} & \\sigma_{\\frac{a,a}{Y=Hombre}}\\end{matrix} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que en la diagonal tenemos la covarianza de cada variable consigo misma, es decir, es la varianza de esta variable. \n",
    "\n",
    "Calculemos $\\Sigma_{Y=Mujer}$ y $\\Sigma_{Y=Hombre}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covMat_mujer = np.cov(data_mujeres,rowvar=False)\n",
    "print('Matriz de covarianza de Mujeres: ')\n",
    "print(covMat_mujer)\n",
    "covMat_hombre = np.cov(data_hombres,rowvar=False)\n",
    "print('Matriz de covarianza de Hombres: ')\n",
    "print(covMat_hombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para parametrizar por completo una distribución gaussiana multivariable, necesitamos también la media de cada variable, según cada modelo generativo. Es decir el peso y la altura promedio de cada género."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_mujer = np.mean(data_mujeres,axis=0)\n",
    "media_hombre = np.mean(data_hombres,axis=0)\n",
    "print('Medias mujeres (gr,cm): ')\n",
    "print(media_mujer) \n",
    "print('Medias hombres (gr,cm): ') \n",
    "print(media_hombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular $P(A,P=a,p | Y=Mujer)$ para el modelo de $Y=Mujer$ en función de la matriz de covarianza $\\Sigma_{Mut=0}$, la media $\\mu_{Mut=0}$, y la cantidad de variables $d$, con la fórmula de la gaussiana multivariable:\n",
    "\n",
    "$$P(A,P=a,p | Y=Mujer) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma_{mujer}|^{1/2}}\\exp\\left(-\\frac{1}{2} (a,p-\\mu_{mujer})^t \\Sigma_{mujer}^{-1} (a,p-\\mu_{mujer})\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "def get_gauss_prob(data, mean_1, mean_2, cov_1, cov_2, N_class_1, N_class_2):\n",
    "    data_np = data\n",
    "    likelihood_class_1 = multivariate_normal.pdf(data_np, mean_1, cov_1)\n",
    "    likelihood_class_2 = multivariate_normal.pdf(data_np, mean_2, cov_2)\n",
    "    prior_1 = N_class_1/(N_class_1 + N_class_2)\n",
    "    prior_2 = N_class_2/(N_class_1 + N_class_2)\n",
    "    total = likelihood_class_1 * prior_1 + likelihood_class_2 * prior_2\n",
    "    p_class_1 = likelihood_class_1 * prior_1/total\n",
    "    p_class_2 = likelihood_class_2 * prior_2/total\n",
    "    return p_class_1, p_class_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 40000 #40kg\n",
    "a = 80000 #0.8m\n",
    "prob_mujer,prob_hombre = get_gauss_prob([p,a], media_mujer, media_hombre, covMat_mujer, covMat_hombre,len(data_mujeres),len(data_hombres))\n",
    "print('Prob de que sea mujer:', prob_mujer)\n",
    "print('Prob de que sea hombre: ',prob_hombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\\begin{aligned} P(y=Mujer|A,P=a,p)> P(y=Hombre|A,P=a,p) \\Leftrightarrow logODDS > 0\\end{aligned}\\end{align} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar cuál modelo tiene mayor probabilidad a posteriori se puede también entender como evaluar el signo del logaritmo del cociente de probabilidades a posteriori, conocido como $logODDS$:\n",
    "$$logODDS = \\log\\left(\\frac{P(y=Mujer|A,P=a,p)}{P(y=Hombre|A,P=a,p)}\\right)$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si asumimos que las matrices de covarianza son iguales para ambas clases, se puede demostrar que, aplicando la fórmula de gaussiana multivariable, la expresión de este logaritmo se reduce a:\n",
    "\n",
    "\n",
    "$$  \\begin{align*} logODDS &= X^{T}[\\Sigma^{-1}( \\mu_{Mut=0} - \\mu_{Mut=1})] + log(\\frac{P(C_0)}{P(C_1)}) - \\frac{1}{2}(\\vec{\\mu}_0+\\vec{\\mu}_1)^T\\Sigma^{-1}(\\vec{\\mu}_0-\\vec{\\mu}_1) \\\\ &= X^{T} w + C \\end{align*}$$\n",
    "\n",
    "La frontera de decisión es una recta, y la decisión depende del signo de logODDS. Es por eso que este método se conoce como **análisis discriminativo lineal (LDA).** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supone $\\Sigma_0=\\Sigma_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_LDA = np.cov(np.vstack([data_hombres - media_hombre, data_mujeres - media_mujer]).T)\n",
    "cov_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_gauss(data, mean_1, mean_2, cov_1, cov_2, N_class_1, N_class_2, name_class_1):\n",
    "    p_class_1, p_class_2 = get_gauss_prob(data[['Peso', 'Altura']].values, mean_1, mean_2, cov_1, cov_2, N_class_1, N_class_2)\n",
    "    return ((p_class_1>p_class_2)==(data['Genero']==name_class_1)).sum()/len(p_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN TRAIN')\n",
    "acc_gauss =  get_acc_gauss(data, media_hombre, media_mujer, covMat_hombre, covMat_mujer,len(data_hombres),len(data_mujeres),name_class_1='Hombre')\n",
    "print('Acc sin asumir matrices de covarianza iguales: ', acc_gauss)\n",
    "acc_LDA =  get_acc_gauss(data, media_hombre, media_mujer, cov_LDA,cov_LDA,len(data_hombres),len(data_mujeres),name_class_1='Hombre')\n",
    "print('Acc asumiendo matrices de covarianza iguales: ', acc_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN TEST')\n",
    "acc_gauss_test =  get_acc_gauss(test, media_hombre, media_mujer, covMat_hombre, covMat_mujer,len(data_hombres), len(data_mujeres),name_class_1='Hombre')\n",
    "print('Acc sin asumir matrices de covarianza iguales: ', acc_gauss_test)\n",
    "acc_LDA_test =  get_acc_gauss(test, media_hombre, media_mujer, cov_LDA,cov_LDA,len(data_hombres),len(data_mujeres),name_class_1='Hombre')\n",
    "print('Acc asumiendo matrices de covarianza iguales: ', acc_LDA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "X = np.linspace(data.min()['Peso'], data.max()['Peso'], N)\n",
    "Y = np.linspace(data.min()['Altura'], data.max()['Altura'], N)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "# Pack X and Y into a single 3-dimensional array\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X\n",
    "pos[:, :, 1] = Y\n",
    "\n",
    "# The distribution on the variables X, Y packed into pos.\n",
    "Z_H_LDA = multivariate_normal.pdf(pos, media_hombre, cov_LDA)\n",
    "Z_M_LDA = multivariate_normal.pdf(pos, media_mujer, cov_LDA)\n",
    "Z_LDA, _ = get_gauss_prob(pos, media_hombre, media_mujer, cov_LDA, cov_LDA,len(data_hombres), len(data_mujeres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "cm = plt.cm.RdBu\n",
    "\n",
    "ax.contourf(X, Y, Z_H_LDA, 256)\n",
    "ax.contourf(X, Y, Z_M_LDA, 256)\n",
    "ax.view_init(70, -90)\n",
    "ax.set_ylabel('Alturas [cms]')\n",
    "ax.set_xlabel('Pesos [kgs]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "cm = plt.cm.RdBu\n",
    "ax.contourf(X, Y, Z_LDA, 256, vmin=0., vmax=1., cmap=cm)\n",
    "ax.set_title('TRAIN: ' + str(np.round(acc_LDA*100)/100) + ' - CV:' + str(np.round(acc_LDA_test*100)/100))\n",
    "ax.set_ylabel('Alturas [cms]')\n",
    "ax.set_xlabel('Pesos [kgs]')\n",
    "ax.view_init(70, -90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.linalg.inv(cov_LDA).dot(media_mujer - media_hombre)\n",
    "C = np.log(data_mujeres.shape[0]/data_hombres.shape[0]) - 0.5*(media_mujer + media_hombre).T.dot(np.linalg.inv(cov_LDA)).dot(media_mujer - media_hombre)\n",
    "\n",
    "logodds_ap=np.array([p,a]).dot(W) + C\n",
    "print(logodds_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Dirías que es hombre o mujer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación ecuación\n",
    "z_teorica = np.zeros([N, N])\n",
    "for row in range(pos.shape[0]):\n",
    "    for col in range(pos.shape[1]):\n",
    "        z_teorica[row, col] = pos[row, col].T.dot(W) + C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación\n",
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.gca()\n",
    "cm = plt.cm.RdBu\n",
    "cf = ax.contourf(X, Y, Z_LDA, 256, alpha=.8, vmin=0., vmax=1., cmap=cm)\n",
    "plt.colorbar(cf, ax=ax)\n",
    "z_levels = np.logspace(-5,-2,10)/4\n",
    "#ax.contour(X, Y, Z_H, z_levels)\n",
    "#ax.contour(X, Y, Z_M, z_levels)\n",
    "\n",
    "#ax.scatter(data_hombres[:,0], data_hombres[:,1], color='b', s=1, label='Hombres')\n",
    "#ax.scatter(data_mujeres[:,0], data_mujeres[:,1], color='r', s=1, label='Mujeres')\n",
    "#Agregar test:\n",
    "ax.scatter(data_hombres_test[:,0], data_hombres_test[:,1], color='c', marker='x', s=1, label='Hombres')\n",
    "ax.scatter(data_mujeres_test[:,0], data_mujeres_test[:,1], color='m', marker='x', s=1, label='Mujeres')\n",
    "ax.contour(X, Y, Z_LDA, (0.5,), colors='k', linewidths=0.25)\n",
    "#ax.contour(X, Y, z_teorica, (0,), colors='k', linewidths=0.25)\n",
    "ax.set_ylabel('Alturas [cms]')\n",
    "ax.set_xlabel('Pesos [kgs]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.gca()\n",
    "cm = plt.cm.RdBu\n",
    "cf = ax.contourf(X, Y, Z_LDA, 256, alpha=.8, vmin=0., vmax=1., cmap=cm)\n",
    "plt.colorbar(cf, ax=ax)\n",
    "z_levels = np.logspace(-5,-2,5)/4\n",
    "ax.contour(X, Y, Z_H_LDA, z_levels, alpha=0.5)\n",
    "ax.contour(X, Y, Z_M_LDA, z_levels, alpha=0.5)\n",
    "ax.contour(X, Y, Z_LDA, (0.5,), colors='k', linewidths=1)\n",
    "ax.scatter(data_hombres[:,0], data_hombres[:,1], color='b', s=1, label='Hombres')\n",
    "ax.scatter(data_mujeres[:,0], data_mujeres[:,1], color='r', s=1, label='Mujeres')\n",
    "ax.set_title('TRAIN: ' + str(np.round(acc_LDA*100)/100) + ' - CV:' + str(np.round(acc_LDA_test*100)/100))\n",
    "ax.set_ylabel('Alturas [cms]')\n",
    "ax.set_xlabel('Pesos [kgs]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Modelo| tipo| Train Acc| CV Acc|Comentarios\n",
    "|-| -| -| -|-|\n",
    "|Histogram - step 0.25|Bayes|0.97|0.68\n",
    "|Histogram - step 0.25|Naive Bayes|0.89|0.88\n",
    "|Histogram - step 0.5|Bayes|0.94|0.82\n",
    "|Histogram - step 0.5|Naive Bayes|0.89|0.88\n",
    "|Histogram - step 1|Bayes|0.92|0.90\n",
    "|Histogram - step 1|Naive Bayes|0.89|0.88\n",
    "|Histogram - step 4|Bayes|0.91|0.92| No generaliza por afuera de la zona de los puntos\n",
    "|Histogram - step 4|Naive Bayes|0.89|0.88\n",
    "|Histogram - step 8|Bayes|0.90|0.90\n",
    "|Histogram - step 8|Naive Bayes|0.87|0.86\n",
    "|Gaussian|Bayes|0.92|0.92|\n",
    "|Gaussian|Naive Bayes|0.89|0.89|\n",
    "|Regresion Logística|-|0.92|0.92|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agregar lo de normalizacion: en RL reduce tiempo de convergencia, en LDA no cambia nada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tomando exponencial de logODDS:\n",
    "$$  \\begin{align*} logODDS &= X^{T} w + C \\\\ \n",
    "\\frac{P(Y=y | X)}{1-P(Y=y|X)} &= e^{X^{T}w + C} \\\\\n",
    " P(Y=y | X) &= (1-P(Y=y | X))e^{X^{T}w + C} \\\\\n",
    "P(Y=y | X) &= e^{X^{T}w + C}  - P(Y=y | X) e^{X^{T}w + C} \\\\\n",
    "P(Y=y | X) & =  e^{X^{T}w + C}  -  e^{X^{T}w + C} e^{X^{T}w + C} \\\\\n",
    "P(Y=y | X) & = \\frac{1}{1 +  e^{-X^{T}w - C}} \\rightarrow \\text{Regresion Logistica} \\end{align*} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando $z=X^{T}w + C$:\n",
    "\n",
    "$$\\begin{align*} P(Y=y | X) &= \\frac{1}{1 +  e^{-z}} \\\\ \n",
    " P(Y=y | X) &= \\frac{1}{1 +  e^{-z}} = \\sigma(z)  \\rightarrow \\text{Función sigmoidea} \\end{align*}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_y_from_LDA(w,c):\n",
    "    z = np.array([np.array(x).dot(w) + c for x in data[['Peso', 'Altura']].values])\n",
    "    z.sort()\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística se puede interpretar como la función sigmoidea aplicada a la frontera de decisión lineal de LDA. Cuanto mayor sea la distancia entre las medias de las clases $\\rightarrow$ mayor es la pendiente en la recta de LDA  $\\rightarrow$ mayor es el módulo de $w$  $\\rightarrow$ mayor es la pendiente de la sigmoidea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "z=get_z_from_LDA(W,C)\n",
    "plt.plot(z,sigmoid(z))\n",
    "\n",
    "print(np.linalg.norm(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "big_W = 100*W\n",
    "print(np.linalg.norm(big_W))\n",
    "y=get_y_from_LDA(big_W,C)\n",
    "plt.plot(y,sigmoid(y))\n",
    "\n",
    "bigger_W = 1000*W\n",
    "print(np.linalg.norm(bigger_W))\n",
    "y=get_y_from_LDA(bigger_W,C)\n",
    "plt.plot(y,sigmoid(y))\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si N es la cantidad de variables (en nuestro caso dos, peso y altura), y asumimos que son independientes, podemos expresar la probabilidad total como el producto:\n",
    "\n",
    "$$\\begin{align*} \\frac{P(Y=0 | X)}{1 - P(Y=0 | X)} &= \\frac{P(X|Y=0) P(Y=0)}{1-P(X|Y=0) P(Y=0)} \\\\ \n",
    "                                                         &= \\frac{\\prod_{i}^{N} P(x_i|Y=0) P(Y=0)}{1 - \\ \\prod_{i}^{N}P(x_i|Y=0) P(Y=0)}  \\end{align*}$$\n",
    "\n",
    "Tomando logaritmo: \n",
    " \n",
    "$$\\begin{align*} logODDS &= \\frac{\\sum_{i}^{N} P(x_i|Y=0) + P(Y=0)}{\\sum_{i}^{N}P(x_i|Y=1) + P(Y=1)}   \\end{align*}$$                                                         \n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$Loss_{\\log}(Y=y, X=x) = -\\log \\operatorname{P}(Y=y|X=x) = -(y \\log (P(Y=y|X=x) + (1 - y) \\log (1 - P(Y=y|X=x)) \\rightarrow \\text{entropía cruzada binaria}$$\n",
    "\n",
    "Si tomo $ P(Y=y | X=x) = \\frac{1}{1 +  e^{-x^{T}w + C}} $ para describir la distribución de probabilidad, lo que busco es minimizar una función convexa.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_Reg = LogisticRegression()\n",
    "log_Reg.fit(data[['Peso', 'Altura']].values, data['Genero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_LR = log_Reg.score(data[['Peso', 'Altura']].values, data['Genero'])\n",
    "print('Train acc:',acc_train_LR)\n",
    "\n",
    "acc_CV_LR = log_Reg.score(test[['Peso', 'Altura']].values, test['Genero'])\n",
    "print('Test acc:',acc_CV_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Reg.predict_proba(test[['Peso', 'Altura']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desvio_hombre = np.std(data_hombres)\n",
    "data_hombres_normalizado = (data_hombres - media_hombre)/desvio_hombre\n",
    "\n",
    "desvio_mujer = np.std(data_mujeres)\n",
    "data_mujeres_normalizado = (data_mujeres - media_mujer)/desvio_mujer\n",
    "\n",
    "data_normalizada = np.concatenate((data_hombres_normalizado,data_mujeres_normalizado),axis=0)\n",
    "print(len(data_normalizada))\n",
    "\n",
    "data_targets=['Hombre']*len(data_hombres_normalizado) + ['Mujer']*len(data_mujeres_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time=time.time()\n",
    "data_all = np.concatenate((data_hombres,data_mujeres),axis=0)\n",
    "log_Reg.fit(data_all, data_targets)\n",
    "end_time=time.time()\n",
    "print('Tiempo de ejecución: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time=time.time()\n",
    "log_Reg.fit(data_normalizada, data_targets)\n",
    "end_time=time.time()\n",
    "print('Tiempo de ejecución: ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Notás un cambio con los datos normalizados? Si aplicás normalización con LDA, ¿se observa alguna diferencia? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
